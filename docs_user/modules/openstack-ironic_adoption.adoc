[id="adopting-the-bare-metal-provisioning-service_{context}"]

//:context: adopting-bare-metal-provisioning
//kgilliga: This module might be converted to an assembly, or a procedure as a standalone chapter.

=  Adopting the Bare Metal Provisioning service

== Prerequisites

* Previous Adoption steps completed. Notably, the service databases
must already be imported into the podified MariaDB, Keystone, Neutron, Glance, and Cinder should be in an operational state. Ideally, Nova has not been adopted yet if Ironic is leveraged in a Bare Metal as a Service configuration.

== Prepare OpenShift

As explained in xref:planning-the-new-deployment_{context}[Planning the new deployment], before deploying OpenStack in OpenShift, you must ensure that the networks are ready, that you have decided the node selection, and also make sure any necessary changes to the OpenShift nodes have been made. For Ironic conductor services, it is necessary that the services be able to reach Baseboard Management Controllers of hardware which is configured to be managed by Ironic. If this hardware is unreachable, the nodes may enter "maintenance" state and be unable to be acted upon until connectivity is restored at a later point in time.

== Variables

Define the shell variables and aliases used in the steps below. The values are
just illustrative, use values that are correct for your environment:

----
alias openstack="oc exec -t openstackclient -- openstack"
----

== Pre-checks

You need the contents of `ironic.conf` file. Download the file so that you can access it locally:

----
$CONTROLLER1_SSH cat /var/lib/config-data/puppet-generated/ironic/etc/ironic/ironic.conf > ironic.conf
----

It is critical that this configuration file comes from one of the controllers and *not* an Undercloud node. The Director Undercloud node specifically operated with different configuration which would not be appropriate or applicable to apply when adopting the Overcloud Ironic deployment.

If adopting the Ironic Inspector service you need the value of the `IronicInspectorSubnets` Director parameter. Use the same values to populate the `dhcpRanges` parameter in the target environment.

== Configurations

As described in xref:planning-the-new-deployment_{context}[Planning the new deployment], Ironic is configured using
configuration snippets instead of using obscure configuration parameters
defined by the installer.

Director generally took care to not override the defaults of Ironic, however as with any system of descreet configuration management attempting to provide a cross-version compatability layer, some configuration was certinly defaulted in particular ways. For example, PXE Loader file names were often overridden at intermediate layers, and you will thus want to pay particular attention to the settings you choose to apply in your adopted deployment. The operator attempts to apply reasonable working default configuraiton, but if you override them with prior configuration, your experience may not be ideal or your new Ironic service will fail to operate. Similarly, additional configuration may be necessary, for example
if your `ironic.conf` has additional hardware types enabled and in use.

Furthermore, the model of reasonable defaults includes commonly used hardware-types and driver interfaces. For example, if you previously needed to enable the `redfish-virtual-media` boot interface and the `ramdisk` deploy interface, the good news is you don't need to, they are enabled by default. One aspect to be on the watch for after completing adoption is when adding new baremetal nodes, the driver interface selection occurs based upon order of presidence in the configuration if not explicitly set on the node creation request or as an established default in `ironic.conf`.

That being said, some configuration parameters are provided as either a convenience to the operator so they don't need to be set on an individual node level while also needing to know precise values, for example, network UUID values, or it is centrally configured in `ironic.conf` as the setting controls behaivor a security control.

The settings, if configured, and formatted as [section] and parameter name, are critical to be maintained from the prior deployment to the new deployment as it will govern quite a bit of the underlying behavior and values in the previous configuration, would have used specific values if
set.

* [neutron]cleaning_network
* [neutron]provisioning_network
* [neutron]rescuing_network
* [neutron]inspection_network
* [conductor]automated_clean
* [deploy]erase_devices_priority
* [deploy]erase_devices_metadata_priority
* [conductor]force_power_state_during_sync
// FIXME: The setting above likely should be True by default in deployments, but would have been *false* by defaults on prior underclouds.

The following parameters *can* be set individually on a node, however, some operators choose to use embedded configuration options to avoid the need to set it individually when creating/managing baremetal nodes. We recommend you check your prior ironic.conf file for these parameters, and if set apply as specific override configuration.

* [conductor]bootloader
* [conductor]rescue_ramdisk
* [conductor]rescue_kernel
* [conductor]deploy_kernel
* [conductor]deploy_ramdisk

Finally, a parameter which may be important based upon your configuration and experience, are the instances of `kernel_append_params`, formerly `pxe_append_params` in the `[pxe]` and `[redfish]` configuration sections. Largely this parameter is used to appy boot time options like "console" for the deployment ramdisk and as such often seeks to be changed.

// TODO:
// Conductor Groups?!

As a warning, hardware types set via the `ironic.conf` `enabled_hardware_types` parameter and hardware type driver interfaces starting with `staging-` are not available to be migrated into an adopted configuration.

Furthermore, Director based deployments made architectural decisions based upon self-management of services. When adopting deployments, you don't necessarilly need multiple replicas of secondary services such as the Introspection service. Should the host the container is running upon fail, OpenShift will restart the container on another host. The short-term transitory loss 

== Procedure - Ironic adoption

=== Applying Initial Configuration

As an initial step patch the OpenStackControlPlane to deploy Ironic:

[source,yaml]
----
oc patch openstackcontrolplane openstack -n openstack --type=merge --patch '
spec:
  ironic:
    enabled: true
    template:
      rpcTransport: oslo
      databaseInstance: openstack
      ironicAPI:
        replicas: 1
        override:
          service:
            internal:
              metadata:
                annotations:
                  metallb.universe.tf/address-pool: internalapi
                  metallb.universe.tf/allow-shared-ip: internalapi
                  metallb.universe.tf/loadBalancerIPs: 172.17.0.80
              spec:
                type: LoadBalancer
      ironicConductors:
      - replicas: 1
        networkAttachments:
          - baremetal
        provisionNetwork: baremetal
        storageRequest: 10G
        customServiceConfig: |
          [neutron]
          cleaning_network=<cleaning network uuid>
          provisioning_network=<provisioning network uuid>
          rescuing_network=<rescuing network uuid>
          inspection_network=<introspection network uuid>
          [conductor]
          automated_clean=true
      ironicInspector:
        replicas: 1
        inspectionNetwork: baremetal
        networkAttachments:
          - baremetal
        dhcpRanges:
          - name: inspector-0
            cidr: 172.20.1.0/24
            start: 172.20.1.190
            end: 172.20.1.199
            gateway: 172.20.1.1
        serviceUser: ironic-inspector
        databaseAccount: ironic-inspector
        passwordSelectors:
          database: IronicInspectorDatabasePassword
          service: IronicInspectorPassword
      ironicNeutronAgent:
        replicas: 1
        rabbitMqClusterName: rabbitmq
      secret: osp-secret
'
----

After applying the this configuration, the operator will begin to apply the configuration and start the necessary Ironic services. Once the services have reached a running state, Ironic will automatically begin polling the power state of baremetal nodes for which it is configured to manage. 

Wait for Ironic control plane services' CRs to become ready:

[source,bash]
----
oc wait --for condition=Ready --timeout=300s ironics.ironic.openstack.org ironic

# Optionally verify the individual services
oc wait --for condition=Ready --timeout=300s ironicapis.ironic.openstack.org ironic-api
oc wait --for condition=Ready --timeout=300s ironicconductors.ironic.openstack.org ironic-conductor
oc wait --for condition=Ready --timeout=300s ironicinspectors.ironic.openstack.org ironic-inspector
oc wait --for condition=Ready --timeout=300s ironicneutronagents.ironic.openstack.org ironic-ironic-neutron-agent
----

=== Updating the DNS Nameservers on the provisoning/cleaning/rescue networks ===

For name resolution to work for ironic operations the DNS nameserver must be set to use the internal DNS servers in the new Openstack Controlplane.

[source,bash]
----
openstack subnet set --dns-nameserver 192.168.122.80 provisioning-subnet
----

=== Role Based Access Control - Navigating upstream improvements

It is critical to note that newer versions of Ironic, by default, contains a more restritive access control model while also becoming multi-tenant aware. By default you may find baremetal nodes missing from a `openstack baremetal node list` command *after* upgrading. Your nodes have not been deleted, but the `owner` field needs to be set on each baremetal node due to the increased access restrictions in the Role Based Access Control model. Because this involves access controls and the model of use which can be site specific, it is highly recommended that you identify the "project" to "own" the baremetal nodes.

In order to see the nodes again, temporarily, you will need to disable the new Role Based Access Control policy, which can then be re-enabled after setting the 'owner' field on nodes.


[source,yaml]
----
oc patch openstackcontrolplane openstack -n openstack --type=merge --patch '
spec:
  ironic:
    enabled: true
    template:
      databaseInstance: openstack
      ironicAPI:
        replicas: 1
        customServiceConfig: |
          [oslo_policy]
          enforce_scope=false
          enforce_new_defaults=false
'
----

Once this configuraiton has applied, the operator will restart the Ironic API service disabling the new RBAC policy which is enabled by default.

After which, you should be able to view baremetal nodes without an `owner` field.

----
openstack baremetal node list -f uuid,provision_state,owner
----

To set these nodes, for example, to the "admin" project, you can execute the following command to assign *all* baremetal nodes with no owner to the admin project.

----
ADMIN_PROJECT_ID=$(openstack project show -c id -f value --domain default admin)
for node in $(openstack baremetal node list -f json -c UUID -c Owner | jq -r '.[] | select(.Owner == null) | .UUID'); do openstack baremetal node set --owner $ADMIN_PROJECT_ID $node; done
----

At which point, you should now be able to re-apply the default access control policy.

[source,yaml]
----
oc patch openstackcontrolplane openstack -n openstack --type=merge --patch '
spec:
  ironic:
    enabled: true
    template:
      databaseInstance: openstack
      ironicAPI:
        replicas: 1
        customServiceConfig: |
          [oslo_policy]
          enforce_scope=true
          enforce_new_defaults=true
'
----

== Post-checks

// TODO, this will need more work

After applying the configuration update to OpenShift, the operator will apply the configuration and start the related services. Ironic will begin to poll power state of the baremetal nodes.

----
openstack endpoint list |grep ironic
openstack baremetal node list
----

The time required for Ironic to review and reconcile the power state of baremetal nodes is dependent upon the number of operating conductors through the `replicas` parameter and which are present in the Ironic deployment being adopted. 
